{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the wine data set\n",
    "# Characteristics: 11 features, 4898 samples, 11 classes (0-10)\n",
    "\n",
    "# Load the data set\n",
    "wine = np.loadtxt('datasets/winequality/winequality-white.csv', delimiter=';', skiprows=1)\n",
    "\n",
    "# extract the data and labels\n",
    "wine_data = []\n",
    "wine_labels = []\n",
    "\n",
    "for row in wine:\n",
    "    wine_data.append(row[:-1])\n",
    "    wine_labels.append(row[-1])\n",
    "\n",
    "# convert to numpy arrays\n",
    "wine_data = np.array(wine_data)\n",
    "wine_labels = np.array(wine_labels)\n",
    "\n",
    "wine_possible_labels = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HAR data set\n",
    "# Characteristics: 561 features, 10299 samples, 6 classes (1-6)\n",
    "\n",
    "# Load the files\n",
    "X_test = np.loadtxt('datasets/UCI HAR Dataset/test/X_test.txt')\n",
    "y_test = np.loadtxt('datasets/UCI HAR Dataset/test/y_test.txt')\n",
    "X_train = np.loadtxt('datasets/UCI HAR Dataset/train/X_train.txt')\n",
    "y_train = np.loadtxt('datasets/UCI HAR Dataset/train/y_train.txt')\n",
    "\n",
    "# format the data set so that all of this data is in one data set due to the given charactersitics\n",
    "har_data = np.concatenate((X_test, X_train), axis=0)\n",
    "har_labels = np.concatenate((y_test, y_train), axis=0)\n",
    "\n",
    "har_possible_labels = np.array([1, 2, 3, 4, 5, 6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement minimum-probability-of-error classifier, assuming the class conditional pdfs are Gaussian\n",
    "# using all available samples from a class, with sample averages, estimate mean vectors and covariance matrices\n",
    "# using sample counts, also estimate class priors\n",
    "\n",
    "# calculate mean vectors, covariance matrices, and priors for each class\n",
    "# also return the unique labels\n",
    "def calculate_parameters(data: np.array, labels: np.array) -> tuple[np.array, np.array, np.array, np.array]:\n",
    "    \"\"\"\n",
    "    Calculates the mean vectors, covariance matrices, and priors for each class.\n",
    "\n",
    "    Args:\n",
    "        data (np.array): The data set.\n",
    "        labels (np.array): The labels for the data set.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.array, np.array, np.array, np.array]: The unique labels, mean vectors, covariance matrices, and priors.\n",
    "    \"\"\"\n",
    "    # get the unique labels\n",
    "    unique_labels = np.unique(labels)\n",
    "\n",
    "    # calculate the mean vectors\n",
    "    mean_vectors = []\n",
    "    for label in unique_labels:\n",
    "        mean_vectors.append(np.mean(data[labels == label], axis=0))\n",
    "\n",
    "    # calculate the covariance matrices\n",
    "    covariance_matrices = []\n",
    "    for label in unique_labels:\n",
    "        covariance_matrices.append(np.cov(data[labels == label].T))\n",
    "\n",
    "    # calculate the priors\n",
    "    priors = []\n",
    "    for label in unique_labels:\n",
    "        priors.append(np.sum(labels == label) / len(labels))\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    mean_vectors = np.array(mean_vectors)\n",
    "    covariance_matrices = np.array(covariance_matrices)\n",
    "    priors = np.array(priors)\n",
    "\n",
    "    return unique_labels, mean_vectors, covariance_matrices, priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean vector and covariance matrix for wine data set\n",
    "wine_unique_labels, wine_mean_vectors, wine_covariance_matrices, wine_priors = calculate_parameters(wine_data, wine_labels)\n",
    "\n",
    "# mean vector and covariance matrix for HAR data set\n",
    "har_unique_labels, har_mean_vectors, har_covariance_matrices, har_priors = calculate_parameters(har_data, har_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a regularization term to the covariance matrices to ensure the regularized covaraince matrix has all eigenvalues larger than 0\n",
    "# this is done by adding a small value to the diagonal of the covariance matrix\n",
    "# for now, we'll use a value on the order of arithmetic average of sample covariance matrices\n",
    "def regularize_covariance_matrices(covariance_matrices: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Regularizes the covariance matrices.\n",
    "\n",
    "    Args:\n",
    "        covariance_matrices (np.array): The covariance matrices.\n",
    "\n",
    "    Returns:\n",
    "        np.array: The regularized covariance matrices.\n",
    "    \"\"\"\n",
    "    # calculate the average covariance matrix\n",
    "    average_covariance_matrix = np.mean(covariance_matrices, axis=0)\n",
    "\n",
    "    # calculate the regularization term\n",
    "    regularization_term = np.mean(np.diag(average_covariance_matrix))\n",
    "\n",
    "    print(\"The regularization term is: \", regularization_term)\n",
    "\n",
    "    # add the regularization term to the covariance matrices\n",
    "    for i in range(len(covariance_matrices)):\n",
    "        covariance_matrices[i] += regularization_term * np.eye(covariance_matrices[i].shape[0])\n",
    "\n",
    "    return covariance_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regularization term is:  353.1966224105839\n",
      "The regularization term is:  0.03549356441569865\n"
     ]
    }
   ],
   "source": [
    "# add the regularization term to the covariance matrices\n",
    "wine_covariance_matrices = regularize_covariance_matrices(wine_covariance_matrices)\n",
    "har_covariance_matrices = regularize_covariance_matrices(har_covariance_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_probability_of_error_classifier(X: np.array, unique_labels: np.array, mean_vectors: np.array, covariance_matrices: np.array, priors: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Implements the minimum-probability-of-error classifier.\n",
    "\n",
    "    Args:\n",
    "        X (np.array): The data set to classify.\n",
    "        unique_labels (np.array): The unique, used labels for the data set.\n",
    "        mean_vectors (np.array): The mean vectors for each class.\n",
    "        covariance_matrices (np.array): The covariance matrices for each class.\n",
    "        priors (np.array): The priors for each class.\n",
    "\n",
    "    Returns:\n",
    "        np.array: The predicted labels for the data set.\n",
    "    \"\"\"\n",
    "    # Calculate the probabilities for all data points and classes\n",
    "    probabilities = np.zeros((X.shape[0], len(unique_labels)))\n",
    "\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        probabilities[:, i] = multivariate_normal.pdf(X, mean_vectors[i], covariance_matrices[i]) * priors[i]\n",
    "\n",
    "    # Find the index of the maximum probability for each data point\n",
    "    max_probability_indices = np.argmax(probabilities, axis=1)\n",
    "\n",
    "    # Use the max_probability_indices to find the predicted labels\n",
    "    predicted_labels = unique_labels[max_probability_indices]\n",
    "\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a function that will count the errors, the error probability estimate, and the confusion matrix\n",
    "def calculate_classification_metrics(predicted_labels: np.array, actual_labels: np.array, possible_labels: np.array) -> tuple[int, float, np.array]:\n",
    "    \"\"\"\n",
    "    Calculates the number of errors, the error probability estimate, and the confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        predicted_labels (np.array): The predicted labels.\n",
    "        actual_labels (np.array): The actual labels.\n",
    "        possible_labels (np.array): All the possible labels for the data set.\n",
    "\n",
    "    Returns:\n",
    "        tuple[int, float, np.array]: The number of errors, the error probability estimate, and the confusion matrix.\n",
    "    \"\"\"\n",
    "    # initialize the number of errors\n",
    "    number_of_errors = 0\n",
    "\n",
    "    # initialize the confusion matrix\n",
    "    confusion_matrix = np.zeros((len(possible_labels), len(possible_labels)), dtype=int)\n",
    "\n",
    "    # iterate through the predicted labels\n",
    "    for i in range(len(predicted_labels)):\n",
    "        # check if the predicted label is correct\n",
    "        if predicted_labels[i] != actual_labels[i]:\n",
    "            # increment the number of errors\n",
    "            number_of_errors += 1\n",
    "\n",
    "        # increment the confusion matrix\n",
    "        actual_index = np.where(possible_labels == actual_labels[i])[0][0]\n",
    "        predicted_index = np.where(possible_labels == predicted_labels[i])[0][0]\n",
    "        confusion_matrix[actual_index, predicted_index] += 1\n",
    "\n",
    "    # calculate the error probability estimate\n",
    "    error_probability_estimate = number_of_errors / len(predicted_labels)\n",
    "\n",
    "    return number_of_errors, error_probability_estimate, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify the wine data set\n",
    "wine_predicted_labels = minimum_probability_of_error_classifier(wine_data, wine_unique_labels, wine_mean_vectors, wine_covariance_matrices, wine_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of errors for the wine data set is:  2683\n",
      "The error probability estimate for the wine data set is:  0.5477746018783177\n",
      "The confusion matrix for the wine data set is:\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    3    0    3   14    0    0    0    0]\n",
      " [   0    0    0    1    0    7  155    0    0    0    0]\n",
      " [   0    0    0    2    0  162 1293    0    0    0    0]\n",
      " [   0    0    0    0    0  148 2050    0    0    0    0]\n",
      " [   0    0    0    0    0   17  863    0    0    0    0]\n",
      " [   0    0    0    0    0    6  169    0    0    0    0]\n",
      " [   0    0    0    0    0    0    5    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# calculate the classification metrics for the wine data set\n",
    "wine_number_of_errors, wine_error_probability_estimate, wine_confusion_matrix = calculate_classification_metrics(wine_predicted_labels, wine_labels, wine_possible_labels)\n",
    "\n",
    "# print the classification metrics for the wine data set\n",
    "print(\"The number of errors for the wine data set is: \", wine_number_of_errors)\n",
    "print(\"The error probability estimate for the wine data set is: \", wine_error_probability_estimate)\n",
    "print(\"The confusion matrix for the wine data set is:\")\n",
    "print(wine_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify the HAR data set\n",
    "har_predicted_labels = minimum_probability_of_error_classifier(har_data, har_unique_labels, har_mean_vectors, har_covariance_matrices, har_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of errors for the HAR data set is:  263\n",
      "The error probability estimate for the HAR data set is:  0.02553645985047092\n",
      "The confusion matrix for the HAR data set is:\n",
      "[[1717    4    1    0    0    0]\n",
      " [   1 1543    0    0    0    0]\n",
      " [   2   53 1351    0    0    0]\n",
      " [   0    1    0 1584  192    0]\n",
      " [   0    0    0    9 1897    0]\n",
      " [   0    0    0    0    0 1944]]\n"
     ]
    }
   ],
   "source": [
    "# calculate the classification metrics for the HAR data set\n",
    "har_number_of_errors, har_error_probability_estimate, har_confusion_matrix = calculate_classification_metrics(har_predicted_labels, har_labels, har_possible_labels)\n",
    "\n",
    "# print the classification metrics for the HAR data set\n",
    "print(\"The number of errors for the HAR data set is: \", har_number_of_errors)\n",
    "print(\"The error probability estimate for the HAR data set is: \", har_error_probability_estimate)\n",
    "print(\"The confusion matrix for the HAR data set is:\")\n",
    "print(har_confusion_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: visualize the data sets in various 2 or 3 dimensional projections\n",
    "# TODO: discuss if gaussian class conditional densities are appropriate for the data sets\n",
    "# TODO: discuss how model choice influences confusion matrix and probability of error\n",
    "# TODO: explain modeling assumptions, how estimated/selected parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
